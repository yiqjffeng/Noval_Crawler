# -*- coding: utf-8 -*-
"""
é…ç½®æ–‡ä»¶ï¼Œå­˜å‚¨çˆ¬è™«éœ€è¦çš„å„ç§é…ç½®å‚æ•°
"""
import datetime
import os
from random import choice
from config import (
    TEMP_OUTPUT_DIRECTORY,
    REQUEST_CONCURRENCY,
    WRITE_CONCURRENCY,
    CONCURRENT_REQUESTS_PER_DOMAIN,
    DOWNLOAD_DELAY,
    RANDOMIZE_DOWNLOAD_DELAY
)
from book_crawler.tools import get_supported_domains

# æ”¯æŒçš„åŸŸååˆ—è¡¨
SUPPORTED_DOMAINS = get_supported_domains()
# é»˜è®¤åŸŸå
DEFAULT_DOMAIN = SUPPORTED_DOMAINS[0]

# å½“å‰åŸŸåï¼ˆä¼šè¢« spider åŠ¨æ€æ›´æ–°ï¼‰
CURRENT_DOMAIN = DEFAULT_DOMAIN

# è¯·æ±‚å¤´é…ç½®ï¼ˆåŸºç¡€å¤´ï¼Œreferer/cookie åœ¨ spider åŠ¨æ€ç”Ÿæˆï¼‰
# è¯·æ±‚å¤´é…ç½®
USER_AGENT = [
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.75 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:65.0) Gecko/20100101 Firefox/65.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.0.3 Safari/605.1.15',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.121 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.140 Safari/537.36 Edge/18.17763'
]

REQUEST_HEADERS = {
    "accept": "application/json",
    "accept-encoding": "gzip, deflate",  # ğŸš« å»æ‰ br å’Œ zstd
    "user-agent": choice(USER_AGENT),
}

# é»˜è®¤å…³é”®è¯
DEFAULT_KEYWORD = "å‰‘æ¥"

KEYWORD = DEFAULT_KEYWORD

# é‡è¯•é…ç½®
MAX_RETRY_TIMES = 3  # æ¯ä¸ªåŸŸåæœ€å¤šé‡è¯•æ¬¡æ•°
MAX_TOTAL_ATTEMPTS = len(SUPPORTED_DOMAINS) * MAX_RETRY_TIMES
RETRY_DELAY = 3  # ç§’

# æ—¥å¿—/è¾“å‡ºé…ç½® - ç¡®ä¿ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•çš„output
TEMP_OUTPUT_DIRECTORY = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'temp')

# æ—¥å¿—ç›®å½•
LOG_DIRECTORY = os.path.join(TEMP_OUTPUT_DIRECTORY, 'log')

ERROR_LOG_FILE = os.path.join(LOG_DIRECTORY, f"{datetime.datetime.now()}.log")

# æœç´¢ç»“æœè¾“å‡ºæ–‡ä»¶
def get_search_output_file(keyword=None):
    """æ ¹æ®å½“å‰å…³é”®è¯åŠ¨æ€ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„"""
    key = keyword or KEYWORD
    return os.path.join(TEMP_OUTPUT_DIRECTORY, f"search_{key}_result.json")

# ç›®å½•çˆ¬è™«é…ç½®
def get_catalog_output_file(keyword=None):
    """æ ¹æ®å½“å‰å…³é”®è¯åŠ¨æ€ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„"""
    key = keyword or KEYWORD
    return os.path.join(TEMP_OUTPUT_DIRECTORY, f"catalog_{key}_result.json")

# å¹¶å‘æ§åˆ¶é…ç½®
REQUEST_CONCURRENCY = REQUEST_CONCURRENCY# è¯·æ±‚å¹¶å‘æ•°ï¼ˆé™ä½ä»¥é¿å…åçˆ¬è™«ï¼‰
WRITE_CONCURRENCY = WRITE_CONCURRENCY  # å†™å…¥å¹¶å‘æ•°
CONCURRENT_REQUESTS_PER_DOMAIN = CONCURRENT_REQUESTS_PER_DOMAIN  # æ¯ä¸ªåŸŸåçš„å¹¶å‘æ•°

# åçˆ¬è™«é…ç½®
DOWNLOAD_DELAY = DOWNLOAD_DELAY  # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
RANDOMIZE_DOWNLOAD_DELAY = RANDOMIZE_DOWNLOAD_DELAY  # éšæœºå»¶è¿ŸèŒƒå›´

# å†…å®¹æ ¼å¼é…ç½®
CHAPTER_SEPARATOR = "\n\n\n--------\n\n\n"  # ç« èŠ‚åˆ†éš”ç¬¦
PARAGRAPH_INDENT = "ã€€ã€€"  # æ®µé¦–ç¼©è¿›

# å†…å®¹é¡µé¢CSSé€‰æ‹©å™¨
CONTENT_CSS_SELECTORS = {
    'title': 'h1::text',  # ç« èŠ‚æ ‡é¢˜é€‰æ‹©å™¨
    'content': '#chaptercontent *::text',  # ç« èŠ‚å†…å®¹é€‰æ‹©å™¨ï¼ˆåŒ…å«æ‰€æœ‰å­å…ƒç´ ï¼‰
    'content_fallback': '.Readarea *::text',  # å†…å®¹å¤‡ç”¨é€‰æ‹©å™¨
    'content_alternative': '.ReadAjax_content *::text'  # ç¬¬ä¸‰å¤‡ç”¨é€‰æ‹©å™¨
}

# ç« èŠ‚è¿‡æ»¤é…ç½®
INVALID_CHAPTER_KEYWORDS = [
    'å±•å¼€å…¨éƒ¨ç« èŠ‚', 'å±•å¼€', 'æ”¶èµ·', '---', '<<<', '>>>',
    'è¿”å›ç›®å½•', 'ä¸Šä¸€é¡µ', 'ä¸‹ä¸€é¡µ', 'é¦–é¡µ', 'å°¾é¡µ', 'ç‚¹æ­¤æŠ¥é”™', 'åŠ å…¥ä¹¦ç­¾',
    'æ”¶è—æœ¬ç«™'
]

INVALID_CHAPTER_PREFIXES = ['å±•å¼€', 'æ”¶èµ·', '<<<', '>>>']

NAVIGATION_KEYWORDS = ['è¯·å‡æ¡', 'å•ç« æ„Ÿè¨€', 'ä½œè€…æœ‰è¯è¯´']

# ç›®å½•çˆ¬å–CSSé€‰æ‹©å™¨é…ç½®
CSS_SELECTORS = {
    'title': 'h1::text',
    'title_fallback': '.info h1::text',
    'author_spans': '.small span::text',
    'chapter_links': '.listmain dl dd a',
    'chapter_title': '::text',
    'chapter_url': '::attr(href)'
}
