#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ¼”ç¤ºç‰ˆæœ¬çš„å†…å®¹çˆ¬è™«ï¼Œä½¿ç”¨æœ¬åœ°HTMLæ–‡ä»¶å±•ç¤ºåŠŸèƒ½
"""
import json
import os
import re
from typing import Dict, List, Any

import book_crawler.config as config


class DemoContentProcessor:
    """æ¼”ç¤ºå†…å®¹å¤„ç†å™¨"""
    
    def __init__(self):
        self.novel_info = {}
        self.chapters = []
        self.completed_chapters = []
    
    def load_catalog(self, catalog_file: str):
        """åŠ è½½ç›®å½•æ–‡ä»¶"""
        with open(catalog_file, 'r', encoding='utf-8') as f:
            catalog_data = json.load(f)
        
        self.novel_info = catalog_data['novel_info']
        self.chapters = catalog_data['chapters']
        
        print(f"åŠ è½½å°è¯´: {self.novel_info['novel_title']}")
        print(f"ä½œè€…: {self.novel_info['author']}")
        print(f"æ€»ç« èŠ‚æ•°: {len(self.chapters)}")
    
    def process_demo_content(self):
        """å¤„ç†æ¼”ç¤ºå†…å®¹"""
        # ä½¿ç”¨novel_content_example.htmlä½œä¸ºæ¼”ç¤ºå†…å®¹
        html_file = "novel_content_example.html"
        if not os.path.exists(html_file):
            print(f"æ¼”ç¤ºHTMLæ–‡ä»¶ä¸å­˜åœ¨: {html_file}")
            return
        
        with open(html_file, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        # æ¨¡æ‹Ÿè§£æHTMLå†…å®¹
        title, content = self._extract_content_from_html(html_content)
        
        if content:
            # ä¸ºæ¯ä¸ªç« èŠ‚åˆ›å»ºæ¼”ç¤ºå†…å®¹
            for i, chapter in enumerate(self.chapters[:3]):  # åªå¤„ç†å‰3ç« ä½œä¸ºæ¼”ç¤º
                chapter_data = {
                    'index': i,
                    'title': f"{chapter['title']}",
                    'content': self._create_demo_content(chapter['title'], content),
                    'url': chapter['url']
                }
                self.completed_chapters.append(chapter_data)
                print(f"å¤„ç†ç« èŠ‚ {i+1}: {chapter['title']}")
        
        # å†™å…¥æ–‡ä»¶
        self._write_to_file()
    
    def _extract_content_from_html(self, html_content: str) -> tuple[str, str]:
        """ä»HTMLä¸­æå–å†…å®¹"""
        # æå–æ ‡é¢˜
        title_match = re.search(r'<h1[^>]*>(.*?)</h1>', html_content, re.DOTALL)
        title = title_match.group(1).strip() if title_match else "æ¼”ç¤ºç« èŠ‚"
        
        # æå–å†…å®¹
        content_match = re.search(r'<div[^>]*id="chaptercontent"[^>]*>(.*?)</div>', html_content, re.DOTALL)
        if content_match:
            raw_content = content_match.group(1)
            # æ¸…ç†HTMLæ ‡ç­¾
            content = re.sub(r'<[^>]+>', '', raw_content)
            content = re.sub(r'&nbsp;', ' ', content)
            content = re.sub(r'&lt;', '<', content)
            content = re.sub(r'&gt;', '>', content)
            content = re.sub(r'&amp;', '&', content)
            
            # æ¸…ç†å¤šä½™çš„ç©ºç™½
            content = re.sub(r'\s+', ' ', content).strip()
            
            return title, content
        
        return title, ""
    
    def _create_demo_content(self, chapter_title: str, base_content: str) -> str:
        """åˆ›å»ºæ¼”ç¤ºå†…å®¹"""
        # åˆ†æ®µå¤„ç†
        sentences = base_content.split('ã€‚')
        paragraphs = []
        
        current_paragraph = ""
        for sentence in sentences:
            sentence = sentence.strip()
            if sentence:
                current_paragraph += sentence + "ã€‚"
                # æ¯3-4å¥è¯åˆ†ä¸€æ®µ
                if len(current_paragraph) > 150:
                    if current_paragraph:
                        # æ·»åŠ æ®µé¦–ç¼©è¿›
                        paragraphs.append(config.PARAGRAPH_INDENT + current_paragraph)
                        current_paragraph = ""
        
        # æ·»åŠ æœ€åä¸€æ®µ
        if current_paragraph:
            paragraphs.append(config.PARAGRAPH_INDENT + current_paragraph)
        
        return '\n\n'.join(paragraphs)
    
    def _write_to_file(self):
        """å†™å…¥æ–‡ä»¶"""
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(config.OUTPUT_DIRECTORY, exist_ok=True)
        
        with open(config.CONTENT_OUTPUT_FILE, 'w', encoding='utf-8') as f:
            # å†™å…¥å°è¯´ä¿¡æ¯
            f.write(f"{self.novel_info['novel_title']}\n")
            f.write(f"ä½œè€…: {self.novel_info.get('author', 'æœªçŸ¥')}\n")
            f.write(f"æ€»ç« èŠ‚æ•°: {self.novel_info['total_chapters']}\n")
            f.write(f"æ¥æº: {self.novel_info['detail_url']}\n")
            f.write("=" * 50 + "\n\n")
            
            # å†™å…¥ç« èŠ‚å†…å®¹
            for i, chapter_data in enumerate(self.completed_chapters):
                # å†™å…¥ç« èŠ‚æ ‡é¢˜
                f.write(f"{chapter_data['title']}\n\n")
                
                # å†™å…¥ç« èŠ‚å†…å®¹
                f.write(chapter_data['content'])
                
                # å†™å…¥ç« èŠ‚åˆ†éš”ç¬¦ï¼ˆé™¤äº†æœ€åä¸€ç« ï¼‰
                if i < len(self.completed_chapters) - 1:
                    f.write(config.CHAPTER_SEPARATOR)
        
        print(f"\næ¼”ç¤ºå†…å®¹å·²ä¿å­˜åˆ°: {config.CONTENT_OUTPUT_FILE}")
        print(f"æˆåŠŸå†™å…¥ {len(self.completed_chapters)} ä¸ªæ¼”ç¤ºç« èŠ‚")
        
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
        file_size = os.path.getsize(config.CONTENT_OUTPUT_FILE)
        print(f"æ–‡ä»¶å¤§å°: {file_size / 1024:.2f} KB")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“š å°è¯´å†…å®¹çˆ¬è™«æ¼”ç¤ºç¨‹åº")
    print("=" * 50)
    
    processor = DemoContentProcessor()
    
    # ä½¿ç”¨æµ‹è¯•ç›®å½•æ–‡ä»¶
    catalog_file = "output/test_catalog.json"
    if not os.path.exists(catalog_file):
        print(f"ç›®å½•æ–‡ä»¶ä¸å­˜åœ¨: {catalog_file}")
        print("è¯·å…ˆè¿è¡Œ: scrapy crawl catalog")
        return
    
    try:
        processor.load_catalog(catalog_file)
        processor.process_demo_content()
        
        print("\nâœ… æ¼”ç¤ºå®Œæˆï¼")
        print(f"ğŸ“– æŸ¥çœ‹ç”Ÿæˆçš„å†…å®¹æ–‡ä»¶: {config.CONTENT_OUTPUT_FILE}")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºé”™: {e}")


if __name__ == "__main__":
    main()